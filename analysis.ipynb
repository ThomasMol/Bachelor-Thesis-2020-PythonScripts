{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitc1b64a04908d4aa0af06e43278af8af3",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_thomas = pd.read_excel('annotations/data_all_thomas.xlsx')\n",
    "data_labels_video_features = pd.read_csv('annotations/combined_labels_video_features.csv')\n",
    "labels = data_labels_video_features[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n",
    "labels_max = labels[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val']]\n",
    "labels_min = labels[['gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n",
    "video_features = data_labels_video_features.drop(['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val'],axis=1)\n",
    "\n",
    "#Applying z normalization\n",
    "video_features.apply(stats.zscore)\n",
    "\n",
    "#Applying L2 normalization\n",
    "video_features = pd.DataFrame(sk.preprocessing.normalize(video_features, norm='l2',axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of feature vector should be 1 after l2 normalization\n",
    "sum_of = sum(map(lambda x : x*x,video_features.iloc[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt')\n",
    "rf.fit(video_features,labels_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=50)\n",
    "tree.fit(video_features, labels_max)\n",
    "print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')\n",
    "export_graphviz(tree, 'tree.dot', rounded = True, feature_names = features, class_names = ['0', '1','2'], filled = True)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=400']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, labels['gold_gt_min_aro'], train_size=660,test_size=300,shuffle=False)\n",
    "\n",
    "#Gridsearching best parameters\n",
    "param_grid = [{ 'kernel': ['linear'],'tol':[1,0.1,0.01,0.001,0.0001]}]\n",
    "#param_grid = [{'C': [1,0.00001], 'kernel': ['linear']}]\n",
    "svc = SVC()\n",
    "#Scoring based on recall macro average score\n",
    "clf = GridSearchCV(svc,param_grid, scoring='recall_macro')\n",
    "clf.fit(X_train,y_train)\n",
    "results = clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best estimator based on param grid search\n",
    "y_pred = clf.best_estimator_.predict(X_test)\n",
    "report_best_estimator = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "variables = [labels['gold_gt_min_aro'],labels['gold_gt_min_like'],labels['gold_gt_min_val'],data_all_thomas['arousal'],data_all_thomas['likeability'],data_all_thomas['valence']]\n",
    "hyperparams_c = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "gammas = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "report_svms = pd.DataFrame(columns=['variable_name'] + gammas)\n",
    "\n",
    "for variable in variables:\n",
    "    row = [variable.name]\n",
    "    for gamma_value in gammas:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(video_features, variable, train_size=660,test_size=300,shuffle=False)\n",
    "        clf_single = SVC(kernel='rbf', C=10, gamma=gamma_value)\n",
    "        clf_single.fit(X_train,y_train)\n",
    "        y_pred_single = clf_single.predict(X_test)\n",
    "        row = row + [recall_score(y_test, y_pred_single,average='macro')]\n",
    "        #report_svms = report_svms.append([[variable.name]])\n",
    "        #report_svms = report_svms.append([recall_score(y_test, y_pred_single,average='macro')])\n",
    "        #report_svms = report_svms.append(pd.DataFrame(classification_report(y_test,y_pred_single, output_dict=True)).transpose())\n",
    "    report_svms = report_svms.append(pd.Series(row,index=report_svms.columns),ignore_index=True)\n",
    "\n",
    "report_svms.to_csv('report_svms_c_l2_zn_rbf.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-108dec7cb513>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_all_thomas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'interview'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m660\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf_single\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclf_single\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred_single\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_single\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_single\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                          accept_large_sparse=False)\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "#single SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, data_all_thomas['interview'] , train_size=660,test_size=300,shuffle=False)\n",
    "clf_single = SVC(kernel='linear', C=1)\n",
    "clf_single.fit(X_train,y_train)\n",
    "y_pred_single = clf_single.predict(X_test)\n",
    "recall_score(y_test, y_pred_single,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, labels['gold_gt_min_val'], train_size=660,test_size=300,shuffle=False)\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "report = classification_report(y_test,y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv('report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots\n",
    "def save_boxplot(x,y):\n",
    "    box_data_1 = data_all_thomas[data_all_thomas[x] == 1 ].get(y)\n",
    "    box_data_2 = data_all_thomas[data_all_thomas[x] == 2 ].get(y)\n",
    "    box_data_3 = data_all_thomas[data_all_thomas[x] == 3 ].get(y)\n",
    "    box_data = [box_data_1,box_data_2,box_data_3]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(box_data)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_xlabel(x)\n",
    "    fig.savefig('boxplots/boxplot_'+x+'_'+y+'.svg')\n",
    "\n",
    "\n",
    "def create_boxplots():\n",
    "    classifications = ['agreeableness','conscientiousness','extraversion','interview','neuroticism','openness']\n",
    "    variables = ['valence','arousal','likeability']\n",
    "    for x in variables:\n",
    "        for y in classifications:\n",
    "            save_boxplot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basis statistics\n",
    "def stats(x):\n",
    "    data_class_1 = data_all_thomas[data_all_thomas[x] == 1 ].get('interview')\n",
    "    data_class_2 = data_all_thomas[data_all_thomas[x] == 2 ].get('interview')\n",
    "    data_class_3 = data_all_thomas[data_all_thomas[x] == 3 ].get('interview')\n",
    "    print('data1: mean=%.3f stdv=%.3f' % (np.mean(data_class_1), np.std(data_class_1)))\n",
    "    print('data2: mean=%.3f stdv=%.3f' % (np.mean(data_class_2), np.std(data_class_2)))\n",
    "    print('data3: mean=%.3f stdv=%.3f' % (np.mean(data_class_3), np.std(data_class_3)))    \n",
    "    stat, p = ttest_ind(data_class_2, data_class_3) \n",
    "    print(stat, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical significance\n",
    "def mannWithNeyuScore():\n",
    "    data_class_1 = data_all_thomas[data_all_thomas['likeability'] == 1 ].get('interview')\n",
    "    data_class_2 = data_all_thomas[data_all_thomas['likeability'] == 2 ].get('interview')\n",
    "    data_class_3 = data_all_thomas[data_all_thomas['likeability'] == 3 ].get('interview')\n",
    "    scipy.stats.mannwhitneyu(data_class_1, data_class_3)"
   ]
  }
 ]
}