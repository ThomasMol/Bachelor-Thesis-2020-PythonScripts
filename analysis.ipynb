{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitc1b64a04908d4aa0af06e43278af8af3",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('bmh')\n",
    "\n",
    "\n",
    "data_all_thomas = pd.read_excel('annotations/data_all_thomas.xlsx')\n",
    "data_labels_video_features = pd.read_csv('annotations/combined_labels_video_features.csv')\n",
    "labels_max = data_labels_video_features[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val']]\n",
    "labels_min = data_labels_video_features[['gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n",
    "video_features = data_labels_video_features.drop(['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val'],axis=1)\n",
    "features = list(video_features.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, labels_max['gold_gt_max_aro'], test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 3  4  3]\n [ 4 33 32]\n [ 1 31 81]]\n              precision    recall  f1-score   support\n\n           1       0.38      0.30      0.33        10\n           2       0.49      0.48      0.48        69\n           3       0.70      0.72      0.71       113\n\n    accuracy                           0.61       192\n   macro avg       0.52      0.50      0.51       192\nweighted avg       0.60      0.61      0.61       192\n\n"
    }
   ],
   "source": [
    "def randomforest_model():\n",
    "    rf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt')\n",
    "    rf.fit(video_features,labels_max)\n",
    "\n",
    "\n",
    "def decisiontree_model():\n",
    "    tree = DecisionTreeClassifier(random_state=50)\n",
    "    tree.fit(video_features, labels_max)\n",
    "    print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')\n",
    "    export_graphviz(tree, 'tree.dot', rounded = True, feature_names = features, class_names = ['0', '1','2'], filled = True)\n",
    "    call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=400']);\n",
    "\n",
    "\n",
    "def svm_model():\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "svm_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxplot(x,y):\n",
    "    box_data_1 = data_all_thomas[data_all_thomas[x] == 1 ].get(y)\n",
    "    box_data_2 = data_all_thomas[data_all_thomas[x] == 2 ].get(y)\n",
    "    box_data_3 = data_all_thomas[data_all_thomas[x] == 3 ].get(y)\n",
    "    box_data = [box_data_1,box_data_2,box_data_3]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(box_data)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_xlabel(x)\n",
    "    fig.savefig('boxplots/boxplot_'+x+'_'+y+'.svg')\n",
    "\n",
    "\n",
    "def create_boxplots():\n",
    "    classifications = ['agreeableness','conscientiousness','extraversion','interview','neuroticism','openness']\n",
    "    variables = ['valence','arousal','likeability']\n",
    "    for x in variables:\n",
    "        for y in classifications:\n",
    "            save_boxplot(x,y)\n",
    "\n",
    "\n",
    "def stats(x):\n",
    "    data_class_1 = data_all_thomas[data_all_thomas[x] == 1 ].get('interview')\n",
    "    data_class_2 = data_all_thomas[data_all_thomas[x] == 2 ].get('interview')\n",
    "    data_class_3 = data_all_thomas[data_all_thomas[x] == 3 ].get('interview')\n",
    "    print('data1: mean=%.3f stdv=%.3f' % (np.mean(data_class_1), np.std(data_class_1)))\n",
    "    print('data2: mean=%.3f stdv=%.3f' % (np.mean(data_class_2), np.std(data_class_2)))\n",
    "    print('data3: mean=%.3f stdv=%.3f' % (np.mean(data_class_3), np.std(data_class_3)))    \n",
    "    stat, p = ttest_ind(data_class_2, data_class_3) \n",
    "    print(stat, p)\n",
    "\n",
    "\n",
    "def mannWithNeyuScore():\n",
    "    data_class_1 = data_all_thomas[data_all_thomas['likeability'] == 1 ].get('interview')\n",
    "    data_class_2 = data_all_thomas[data_all_thomas['likeability'] == 2 ].get('interview')\n",
    "    data_class_3 = data_all_thomas[data_all_thomas['likeability'] == 3 ].get('interview')\n",
    "    scipy.stats.mannwhitneyu(data_class_1, data_class_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}