{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitc1b64a04908d4aa0af06e43278af8af3",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('bmh')\n",
    "\n",
    "data_all_thomas = pd.read_excel('../annotations/data_all_thomas.xlsx')\n",
    "data_labels_video_features = pd.read_csv('../annotations/combined_labels_video_features.csv')\n",
    "labels = data_labels_video_features[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n",
    "#labels_max = labels[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val']]\n",
    "#labels_min = labels[['gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video features, No Normalization\n",
    "video_features = data_labels_video_features.drop(['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying z normalization\n",
    "video_features = video_features.apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying L2 normalization\n",
    "video_features = pd.DataFrame(sk.preprocessing.normalize(video_features, norm='l2',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and converting train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, data_all_thomas.agreeableness_binary, train_size=440,test_size=220,shuffle=False)\n",
    "\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Fold Cross Validation KELM\n",
    "from sklearn.model_selection import KFold\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "variables_fold = [data_all_thomas.interview_binary[:660], data_all_thomas.agreeableness_binary[:660], data_all_thomas.openness_binary[:660], data_all_thomas.neuroticism_binary[:660], data_all_thomas.extraversion_binary[:660], data_all_thomas.conscientiousness_binary[:660], data_all_thomas.arousal[:660], data_all_thomas.valence[:660], data_all_thomas.likeability[:660]]\n",
    "hyperparams_c = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "report_kelms = pd.DataFrame(columns=['variable'] + hyperparams_c)\n",
    "\n",
    "\n",
    "for variable in variables_fold:\n",
    "    kfold = KFold(3,False,None)\n",
    "    name = variable.name\n",
    "    variable = variable.to_numpy()\n",
    "    for train, test in kfold.split(variable):\n",
    "        row = [name]\n",
    "        for c in hyperparams_c:\n",
    "            kelm = elm.Extreme_Learning_Machine(kernel=\"linear\",weighted=True,C=c, model_type=\"classification\")\n",
    "            kelm.train(video_features.iloc[train].to_numpy(),variable[train])\n",
    "            y_predict = kelm.test(video_features.iloc[test].to_numpy())\n",
    "            score = recall_score(variable[test], y_predict,average='macro')            \n",
    "            row = row + [score]\n",
    "        report_kelms = report_kelms.append(pd.Series(row,index=report_kelms.columns),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_kelms.to_csv('report_all_variables_fold_cv_weighted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Model fusion\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create dataframe to store predictions\n",
    "report_3_model = pd.DataFrame()\n",
    "\n",
    "# Dimensions to use\n",
    "variables_fold = pd.DataFrame([data_all_thomas.interview_binary[:660], data_all_thomas.agreeableness_binary[:660], data_all_thomas.openness_binary[:660], data_all_thomas.neuroticism_binary[:660], data_all_thomas.extraversion_binary[:660], data_all_thomas.conscientiousness_binary[:660], data_all_thomas.arousal[:660], data_all_thomas.valence[:660], data_all_thomas.likeability[:660]]).transpose()\n",
    "\n",
    "# Choose dimension\n",
    "dimension = variables_fold.interview_binary\n",
    "\n",
    "# Best C params, dimension and fold specific\n",
    "hyperparams_c = [100,100,1000]\n",
    "\n",
    "# Create fold\n",
    "kfold = KFold(3,False,None)\n",
    "\n",
    "# Loop through folds\n",
    "for index, (train_index, test_index) in enumerate(kfold.split(dimension)):\n",
    "    # Loop through hyperparam, in order of fold (check csv)\n",
    "    kelm = elm.Extreme_Learning_Machine(kernel=\"linear\",weighted=True,C=hyperparams_c[index], model_type=\"classification\")\n",
    "    X_train, X_test = video_features.iloc[train_index].to_numpy(), video_features.iloc[test_index].to_numpy()\n",
    "    y_train, y_test = dimension[train_index].to_numpy(), dimension[test_index].to_numpy()\n",
    "    kelm.train(X_train, y_train)\n",
    "    # Get predictions of single fold (to check if correct model)\n",
    "    y_prediction_fold = kelm.test(X_test)\n",
    "    fold_score = recall_score(y_test, y_prediction_fold, average=\"macro\")\n",
    "    # Get predictions of 660 rows, creates test set per fold model\n",
    "    y_predictions_all = kelm.test(video_features.iloc[:660].to_numpy())   \n",
    "    report_3_model[index] = [fold_score] + y_predictions_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_kelms.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single ELM\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "elmk = elm.Extreme_Learning_Machine(kernel=\"linear\",weighted=False,C=1, model_type=\"classification\")\n",
    "#beta = elmk.train(X_train,y_train)\n",
    "#y_predict = elmk.test(X_test)\n",
    "#recall_score(y_test, y_predict,average='macro')\n",
    "#mean_squared_error(y_test,y_predict,squared=False)\n",
    "#mean_absolute_error(y_test,y_predict)\n",
    "scores = cross_val_score(elm, X_train,y_train, cv=3, scoring=\"recall_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree pre-processing\n",
    "# Converting categorical variables to one-hot encoding\n",
    "arousal_dummy = pd.get_dummies(data_all_thomas[['arousal']].astype(str))[:660].to_numpy()\n",
    "valence_dummy = pd.get_dummies(data_all_thomas[['valence']].astype(str))[:660].to_numpy()\n",
    "likeability_dummy = pd.get_dummies(data_all_thomas[['likeability']].astype(str))[:660].to_numpy()\n",
    "\n",
    "arousal_weighted = arousal_dummy * beta_arousal\n",
    "valence_weighted = valence_dummy * beta_valence\n",
    "likeability_weighted = likeability_dummy * beta_likeability\n",
    "\n",
    "x_train_mood_weighted_categorical = np.concatenate((arousal_weighted, valence_weighted, likeability_weighted), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "x_train_bin = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary']]\n",
    "y_train_bin = data_all_thomas[['interview_binary']][:660]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt', max_depth=4)\n",
    "rf.fit(x_train_mood_weighted_categorical,y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "\n",
    "\n",
    "person_bin = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary']]\n",
    "mood_cat = data_all_thomas[['arousal','valence','likeability']]\n",
    "mood_person_combined = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary','arousal','valence','likeability']]\n",
    "interview_bin = data_all_thomas[['interview_binary']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mood_person_combined, interview_bin, train_size=660,test_size=300,shuffle=False)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=50, max_depth=9, min_samples_leaf=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "recall_score(y_test, y_predict, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generete dot file for tree and visualize using graphviz\n",
    "import graphviz \n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=mood_person_combined.columns,class_names=['not invited','invited'],filled=True, rounded=True,special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ELM\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "\n",
    "\n",
    "variables_mood = [labels['gold_gt_min_aro'],labels['gold_gt_min_like'],labels['gold_gt_min_val'],data_all_thomas['arousal'],data_all_thomas['likeability'],data_all_thomas['valence']]\n",
    "variables_personality_binary = [data_all_thomas.agreeableness_binary, data_all_thomas.conscientiousness_binary, data_all_thomas.extraversion_binary, data_all_thomas.neuroticism_binary, data_all_thomas.openness_binary, data_all_thomas.interview_binary]\n",
    "variables_personality_continuous = [data_all_thomas.agreeableness, data_all_thomas.conscientiousness, data_all_thomas.extraversion, data_all_thomas.neuroticism, data_all_thomas.openness, data_all_thomas.interview]\n",
    "\n",
    "hyperparams_c = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "gammas = [100,10,1,0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
    "weights = [True, False]\n",
    "\n",
    "report_kelms = pd.DataFrame(columns=['variable'] + hyperparams_c)\n",
    "\n",
    "for weight in weights:\n",
    "    for variable in variables_personality_binary:\n",
    "        row = [str(weight) + ' - ' + variable.name]\n",
    "        for c_var in hyperparams_c:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(video_features, variable, train_size=660,test_size=300,shuffle=False)\n",
    "            X_train = X_train.to_numpy()\n",
    "            X_test = X_test.to_numpy()\n",
    "            y_train = y_train.to_numpy()\n",
    "            y_test = y_test.to_numpy()\n",
    "            kelm = elm.Extreme_Learning_Machine(C=c_var, kernel='linear', weighted=weight, model_type=\"classification\")\n",
    "            kelm.train(X_train,y_train)\n",
    "            y_pred_single = kelm.test(X_test)\n",
    "            row = row + [recall_score(y_test, y_pred_single,average='macro')]\n",
    "        report_kelms = report_kelms.append(pd.Series(row,index=report_kelms.columns),ignore_index=True)\n",
    "\n",
    "\n",
    "report_kelms.to_csv('report_personality_kelm_linear_weighted_c_binary_l2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ELM "
   ]
  }
 ]
}