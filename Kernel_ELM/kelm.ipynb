{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitc1b64a04908d4aa0af06e43278af8af3",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('bmh')\n",
    "\n",
    "data_all_thomas = pd.read_excel('../annotations/data_all_thomas.xlsx')\n",
    "data_labels_video_features = pd.read_csv('../annotations/combined_labels_video_features.csv')\n",
    "labels = data_labels_video_features[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n",
    "#labels_max = labels[['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val']]\n",
    "#labels_min = labels[['gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video features, No Normalization\n",
    "video_features = data_labels_video_features.drop(['gold_gt_max_aro','gold_gt_max_like','gold_gt_max_val','gold_gt_min_aro','gold_gt_min_like','gold_gt_min_val'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying z normalization\n",
    "video_features = video_features.apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying L2 normalization\n",
    "video_features = pd.DataFrame(sk.preprocessing.normalize(video_features, norm='l2',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and converting train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(video_features, data_all_thomas.agreeableness_binary, train_size=440,test_size=220,shuffle=False)\n",
    "\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "whoopise = [data_all_thomas.interview_binary[:660].to_numpy(), data_all_thomas.agreeableness_binary[:660].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "UAR: 0.6547500827540549\nUAR: 0.5889093342254934\nUAR: 0.6448281846581048\nUAR: 0.6547500827540549\nUAR: 0.5889093342254934\nUAR: 0.6448281846581048\nUAR: 0.6547500827540549\nUAR: 0.5889093342254934\nUAR: 0.6448281846581048\nUAR: 0.6597980801059251\nUAR: 0.5930076948812312\nUAR: 0.6448281846581048\nUAR: 0.6645150612380006\nUAR: 0.6124121779859485\nUAR: 0.6527247483512669\nUAR: 0.7093677590201919\nUAR: 0.6513047842087655\nUAR: 0.6377993752169386\nUAR: 0.6607911287653094\nUAR: 0.6329876212780194\nUAR: 0.6228740020826102\nUAR: 0.6152763985435286\nUAR: 0.5726831716293075\nUAR: 0.6398819854217286\nUAR: 0.5744786494538232\nUAR: 0.5808798929407829\nUAR: 0.6419645956265185\nUAR: 0.5741476332340285\nUAR: 0.5808798929407829\nUAR: 0.6324192988545644\nUAR: 0.5741476332340285\nUAR: 0.5808798929407829\nUAR: 0.6324192988545644\nUAR: 0.6385093167701863\nUAR: 0.4964797586120191\nUAR: 0.5780304966351478\nUAR: 0.6385093167701863\nUAR: 0.4964797586120191\nUAR: 0.5780304966351478\nUAR: 0.6385093167701863\nUAR: 0.5005447992624256\nUAR: 0.5741545276428998\nUAR: 0.6389233954451345\nUAR: 0.504609839912832\nUAR: 0.5764119601328903\nUAR: 0.6385093167701863\nUAR: 0.5181879138379013\nUAR: 0.5945140131186644\nUAR: 0.6393374741200828\nUAR: 0.5761880814684435\nUAR: 0.5922565806286737\nUAR: 0.5763975155279504\nUAR: 0.5629033609923728\nUAR: 0.6048641281199421\nUAR: 0.487991718426501\nUAR: 0.5555695247674126\nUAR: 0.6345940880824602\nUAR: 0.487991718426501\nUAR: 0.5566591232922639\nUAR: 0.6119771701167049\nUAR: 0.487991718426501\nUAR: 0.5618137624675216\nUAR: 0.6119771701167049\nUAR: 0.487991718426501\nUAR: 0.565878803117928\nUAR: 0.6042252321322089\n"
    }
   ],
   "source": [
    "# 3 Fold Cross Validation KELM\n",
    "from sklearn.model_selection import KFold\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "variables = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary','interview_binary','arousal','valence','likeability']][:660]\n",
    "hyperparams_c = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "\n",
    "\n",
    "for variable in whoopise:\n",
    "    kfold = KFold(3,False,1)\n",
    "    for c in hyperparams_c:\n",
    "        for train, test in kfold.split(variable):\n",
    "            kelm = elm.Extreme_Learning_Machine(kernel=\"linear\",weighted=False,C=c, model_type=\"classification\")\n",
    "            kelm.train(video_features.iloc[train].to_numpy(),variable[train])\n",
    "            y_predict = kelm.test(video_features.iloc[test].to_numpy())\n",
    "            score = recall_score(variable[test], y_predict,average='macro')\n",
    "            print('UAR: %s' % (score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single ELM\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "elmk = elm.Extreme_Learning_Machine(kernel=\"linear\",weighted=False,C=1, model_type=\"classification\")\n",
    "#beta = elmk.train(X_train,y_train)\n",
    "#y_predict = elmk.test(X_test)\n",
    "#recall_score(y_test, y_predict,average='macro')\n",
    "#mean_squared_error(y_test,y_predict,squared=False)\n",
    "#mean_absolute_error(y_test,y_predict)\n",
    "scores = cross_val_score(elm, X_train,y_train, cv=3, scoring=\"recall_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree pre-processing\n",
    "# Converting categorical variables to one-hot encoding\n",
    "arousal_dummy = pd.get_dummies(data_all_thomas[['arousal']].astype(str))[:660].to_numpy()\n",
    "valence_dummy = pd.get_dummies(data_all_thomas[['valence']].astype(str))[:660].to_numpy()\n",
    "likeability_dummy = pd.get_dummies(data_all_thomas[['likeability']].astype(str))[:660].to_numpy()\n",
    "\n",
    "arousal_weighted = arousal_dummy * beta_arousal\n",
    "valence_weighted = valence_dummy * beta_valence\n",
    "likeability_weighted = likeability_dummy * beta_likeability\n",
    "\n",
    "x_train_mood_weighted_categorical = np.concatenate((arousal_weighted, valence_weighted, likeability_weighted), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "x_train_bin = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary']]\n",
    "y_train_bin = data_all_thomas[['interview_binary']][:660]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt', max_depth=4)\n",
    "rf.fit(x_train_mood_weighted_categorical,y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "\n",
    "\n",
    "person_bin = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary']]\n",
    "mood_cat = data_all_thomas[['arousal','valence','likeability']]\n",
    "mood_person_combined = data_all_thomas[['agreeableness_binary','conscientiousness_binary','extraversion_binary','neuroticism_binary','openness_binary','arousal','valence','likeability']]\n",
    "interview_bin = data_all_thomas[['interview_binary']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mood_person_combined, interview_bin, train_size=660,test_size=300,shuffle=False)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=50, max_depth=9, min_samples_leaf=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "recall_score(y_test, y_predict, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generete dot file for tree and visualize using graphviz\n",
    "import graphviz \n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=mood_person_combined.columns,class_names=['not invited','invited'],filled=True, rounded=True,special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ELM\n",
    "import kernel_elm as elm\n",
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score\n",
    "\n",
    "\n",
    "variables_mood = [labels['gold_gt_min_aro'],labels['gold_gt_min_like'],labels['gold_gt_min_val'],data_all_thomas['arousal'],data_all_thomas['likeability'],data_all_thomas['valence']]\n",
    "variables_personality_binary = [data_all_thomas.agreeableness_binary, data_all_thomas.conscientiousness_binary, data_all_thomas.extraversion_binary, data_all_thomas.neuroticism_binary, data_all_thomas.openness_binary, data_all_thomas.interview_binary]\n",
    "variables_personality_continuous = [data_all_thomas.agreeableness, data_all_thomas.conscientiousness, data_all_thomas.extraversion, data_all_thomas.neuroticism, data_all_thomas.openness, data_all_thomas.interview]\n",
    "\n",
    "hyperparams_c = [100000,10000,1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "gammas = [100,10,1,0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
    "weights = [True, False]\n",
    "\n",
    "report_kelms = pd.DataFrame(columns=['variable'] + hyperparams_c)\n",
    "\n",
    "for weight in weights:\n",
    "    for variable in variables_personality_binary:\n",
    "        row = [str(weight) + ' - ' + variable.name]\n",
    "        for c_var in hyperparams_c:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(video_features, variable, train_size=660,test_size=300,shuffle=False)\n",
    "            X_train = X_train.to_numpy()\n",
    "            X_test = X_test.to_numpy()\n",
    "            y_train = y_train.to_numpy()\n",
    "            y_test = y_test.to_numpy()\n",
    "            kelm = elm.Extreme_Learning_Machine(C=c_var, kernel='linear', weighted=weight, model_type=\"classification\")\n",
    "            kelm.train(X_train,y_train)\n",
    "            y_pred_single = kelm.test(X_test)\n",
    "            row = row + [recall_score(y_test, y_pred_single,average='macro')]\n",
    "        report_kelms = report_kelms.append(pd.Series(row,index=report_kelms.columns),ignore_index=True)\n",
    "\n",
    "\n",
    "report_kelms.to_csv('report_personality_kelm_linear_weighted_c_binary_l2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ELM "
   ]
  }
 ]
}